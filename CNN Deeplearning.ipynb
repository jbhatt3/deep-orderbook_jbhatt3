{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = 'content/coinbase_btc_usd/coinbase/btc_usd/l2_snapshots/100ms/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_snapshot = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "day = pd.DataFrame()\n",
    "i = 0\n",
    "for x in os.listdir(paths):\n",
    "    path = paths+x\n",
    "    temp = pd.read_parquet(path)\n",
    "    if count%24 == 0:\n",
    "        day = pd.read_parquet(path)\n",
    "    else:\n",
    "        day = pd.concat([day,temp])\n",
    "  \n",
    "    i+=1\n",
    "    count +=1\n",
    "\n",
    "    if count%24 == 0:\n",
    "        flag = not register\n",
    "        day = day.dropna()\n",
    "        print(day.shape)\n",
    "        result = []\n",
    "        for cols in day.columns:\n",
    "            values = day[cols].to_numpy()\n",
    "            mean = np.mean(values)\n",
    "            std = np.std(values)\n",
    "            result.append([cols,[mean,std]])\n",
    "        register[count/24] = result\n",
    "        if not flag:\n",
    "            for l in range(200):\n",
    "                prev_stat = register[(count/24)-1]\n",
    "                col_name = prev_stat[l][0]\n",
    "                col_mean = prev_stat[l][1][0]\n",
    "                col_std = prev_stat[l][1][1]\n",
    "                values = day[col_name].to_numpy()\n",
    "                values = (values - col_mean)/col_std\n",
    "                day[col_name] = values\n",
    "            l2_snapshot = pd.concat([day,l2_snapshot])\n",
    "        del day\n",
    "  \n",
    "    if i>240:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_snapshot_ = l2_snapshot[['b1','b2','b3','b4','b5','b6','b7','b8', 'b9', 'b10', 'a1','a2','a3','a4','a5','a6','a7','a8', 'a9', 'a10', 'bq1','bq2','bq3','bq4','bq5','bq6','bq7','bq8', 'bq9', 'bq10', 'aq1','aq2','aq3','aq4','aq5','aq6','aq7','aq8', 'aq9', 'aq10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_labels(df,ask, bid,k=20, alpha = 10e-5):\n",
    "    df_ = df.copy()\n",
    "    df_['mid_price'] = (df_[ask].to_numpy()+df_[bid].to_numpy())/2\n",
    "    df_['target'] = 1\n",
    "    index = df_.columns.get_loc('mid_price')\n",
    "    target_index = df_.columns.get_loc('target')\n",
    "    shape = df_.shape[0]\n",
    "    y = df_['target'].to_numpy()\n",
    "    for i in tqdm(range(k,shape-k)):\n",
    "        if i==k:\n",
    "            m_b = np.mean(df_.iloc[(i-k):i, index].to_numpy())\n",
    "            m_a = np.mean(df_.iloc[i+1:(i+k+1), index].to_numpy())\n",
    "            val = df_.iloc[i-k,index]\n",
    "            valB = df_.iloc[i+1, index]\n",
    "        else:\n",
    "            curr_val = df_.iloc[i-1,index]\n",
    "            curr_valB = df_.iloc[i+k, index]\n",
    "            m_b = (m_b*k+(curr_val)-(val))/k\n",
    "            m_a = (m_a*k+(curr_valB - valB))/k\n",
    "            val = df_.iloc[(i-k),index]\n",
    "            valB = df_.iloc[(i+1), index]\n",
    "\n",
    "        if (m_b > m_a*(1+alpha)):\n",
    "            y[i] = 2\n",
    "        if (m_b < m_a*(1-alpha)):\n",
    "            y[i] = 0\n",
    "\n",
    "    y = y[k:shape-k]\n",
    "    X = df.iloc[k:shape-k,:].to_numpy()\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch\n",
    "min_ = float('inf')\n",
    "minI = 0\n",
    "for i in np.logspace(-5,-20,20, endpoint = True):\n",
    "    X,y = generate_features_labels(l2_snapshot, ask='a1', bid = 'b1', alpha=i)\n",
    "    y_ = pd.Series(y)\n",
    "    temp = y_.value_counts()\n",
    "    a,b,c = temp[0], temp[1], temp[2]\n",
    "    sum_ = a+b+c\n",
    "    l2 = ((((1/3-(a/sum_)))**2 + ((1/3-(b/sum_)))**2 + ((1/3-(c/sum_)))**2)/3)**2\n",
    "    if l2 < min_:\n",
    "        min_ = l2\n",
    "        minI = i\n",
    "    print(min_, minI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(minI, min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = generate_features_labels(l2_snapshot_, ask='a1', bid = 'b1', alpha=7.847599703514623e-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_snapshot_['mid_price'] = (l2_snapshot_['b1']+l2_snapshot_['a1'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,15))\n",
    "plt.plot(np.arange(1,l2_snapshot_.shape[0]+1), l2_snapshot_['mid_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "D = 40\n",
    "N = len(X) - T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPart = 3176026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "X_train = np.zeros((trainPart, T, D), dtype = 'float32')\n",
    "y_train = np.zeros(trainPart, dtype='float32')\n",
    "\n",
    "#Preparing the time series data using timestep of 100 and no of features = 200\n",
    "for t in range(trainPart):\n",
    "    X_train[t, :, :] = X[t:t+T]\n",
    "    y_train[t] = y[t+T] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print('X_train - Before: {} GB'.format(X_train.nbytes/1024**3), X_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print('y_train - Before: {} GB'.format(y_train.nbytes/1024**3), y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "X_test = np.zeros((N - trainPart, T, D), dtype = 'float32')\n",
    "y_test = np.zeros(N - trainPart, dtype='float32')\n",
    "\n",
    "#Preparing the time series data using timestep of 100 and no of features = 40\n",
    "for k in range(N - trainPart):\n",
    "    t = k + trainPart\n",
    "    X_test[k, :, :] = X[t:t+T]\n",
    "    y_test[k] = y[t+T]\n",
    "\n",
    "print('X_test - Before: {} GB'.format(X_test.nbytes/1024**3), X_test.dtype)\n",
    "print('y_test - Before: {} GB'.format(y_test.nbytes/1024**3), y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, Conv2D, Flatten, MaxPooling1D, MaxPooling2D, Dense, LeakyReLU, Bidirectional, LSTM, Add, Activation, GlobalAveragePooling1D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "## Resnet of Conv1D\n",
    "DefaultConv1D = partial(keras.layers.Conv1D, kernel_size=4, strides=1,\n",
    "                        padding=\"SAME\", use_bias=False)\n",
    "\n",
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            DefaultConv1D(filters, strides=strides),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            DefaultConv1D(filters),\n",
    "            keras.layers.BatchNormalization()]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                DefaultConv1D(filters, kernel_size=1, strides=strides),\n",
    "                keras.layers.BatchNormalization()]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        return self.activation(Z + skip_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    inputs = keras.layers.Input(shape = (100,40))\n",
    "    x = keras.layers.Conv1D(filters=16, kernel_size=4 ,activation='relu', padding='SAME')(inputs)\n",
    "    x = keras.layers.MaxPooling1D(2)(x)\n",
    "    \n",
    "    prev_filters = 16\n",
    "    for filters in [16]*3+[32]*2:\n",
    "        if prev_filters != filters:\n",
    "            stride = 2\n",
    "        else:\n",
    "            stride = 1\n",
    "        x = ResidualUnit(filters, stride)(x)\n",
    "        prev_filters = filters\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "    res_net_model = keras.models.Model(inputs, outputs)\n",
    "    res_net_model.compile(optimizer='adam',\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# with strategy.scope():\n",
    "#     i = Input(shape=X_train[0].shape)\n",
    "    \n",
    "#     x = Conv2D(16, (4,D),kernel_initializer=\"he_normal\")(i)\n",
    "#     x = LeakyReLU(alpha=0.01)(x)\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "#     x = tf.keras.layers.Reshape(target_shape=(T-3,16))(x)\n",
    "    \n",
    "#     x = Conv1D(16, 4, kernel_initializer=\"he_normal\")(x)\n",
    "#     x = LeakyReLU(alpha=0.01)(x)\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     x = MaxPooling1D(2)(x)\n",
    "    \n",
    "#     x = Conv1D(32, 3, activation=LeakyReLU(alpha=0.01), kernel_initializer=\"he_normal\")(x)\n",
    "#     x = LeakyReLU(alpha=0.01)(x)\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     x = MaxPooling1D(2)(x)\n",
    "    \n",
    "#     x = Bidirectional(LSTM(64, return_sequences = False))(x)\n",
    "    \n",
    "#     x = Dense(32 ,kernel_initializer=\"he_normal\")(x)\n",
    "#     x = LeakyReLU(alpha=0.01)(x)\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "#     x = Dense(32, kernel_initializer=\"he_normal\")(x)\n",
    "#     x = LeakyReLU(alpha=0.01)(x)\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "#     x = Dense(3, activation='softmax', kernel_initializer=\"he_normal\")(x)\n",
    "\n",
    "#     model = Model(i,x)\n",
    "#     model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "with tf.device('/CPU:0'):\n",
    "    r = res_net_model.fit(\n",
    "        X_train,y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "res_net_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "y_pred = res_net_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x=range(1,EPOCHS+1),y=r.history['loss'])\n",
    "#sns.lineplot(x=range(1,EPOCHS+1),y=r.history['val_loss'])\n",
    "plt.title('Model Cross Entropy Loss')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    y_pred = model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    \n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "ax=sns.heatmap(cm, annot=True, xticklabels=[0,1,2], yticklabels=[0,1,2], cmap='Blues')\n",
    "ax.set_ylim(3.0, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
